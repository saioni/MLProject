{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCsv(filename):\n",
    "    lines=csv.reader(open(filename, 'r'))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [x for x in dataset[i]]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std(numbers):\n",
    "    if len(numbers) == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        avg = mean(numbers)\n",
    "        variance = sum([pow(x-avg,2) for x in numbers]) / float(len(numbers)-1)\n",
    "        return math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(dataset, sRatio):\n",
    "    trainSize = int(len(dataset) * sRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return [trainSet, copy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(dataset):\n",
    "    foreveryclass=[]\n",
    "    for attribute in zip(*dataset):\n",
    "        x = mean(attribute)\n",
    "        y = std(attribute)\n",
    "        foreveryclass.append([x,y])\n",
    "    del foreveryclass[-1]\n",
    "    return foreveryclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassData(dataset):\n",
    "    classdivision = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if(vector[-1] not in classdivision):\n",
    "            classdivision[vector[-1]] = []\n",
    "        classdivision[vector[-1]].append(vector)\n",
    "    return classdivision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(dataset):\n",
    "    divided = ClassData(dataset)\n",
    "    PValues = {}\n",
    "    for classValue, instances in divided.items():\n",
    "        PValues[classValue] = process(instances)\n",
    "    return PValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prob(x, mean, stdev):\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassProb(ProcessValues, inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in ProcessValues.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = inputVector[i]\n",
    "            probabilities[classValue] *=Prob(x,mean,stdev)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ProcessValues , inputVector):\n",
    "    probabilities = ClassProb(ProcessValues, inputVector)\n",
    "    bestLabel , bestProb = None,-1\n",
    "    for classValue , probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(ProcessValue , testSet):\n",
    "    predictions = []\n",
    "    y_true = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(ProcessValue , testSet[i])\n",
    "        predictions.append(result)\n",
    "    for i in range(len(testSet)):\n",
    "        vector = testSet[i]\n",
    "        y_true.append(vector[-1])\n",
    "    return [y_true , predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet , predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i]:\n",
    "            correct +=1\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnvrt2flot(dataset):\n",
    "    d=[]\n",
    "    for i in dataset:\n",
    "        d.append(list(map(float,i)))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main(dataset):\n",
    "    sRatio = 0.80\n",
    "    #dataset = loadCsv(file)\n",
    "    #dataset = dataset[1:]\n",
    "    #dataset = cnvrt2flot(dataset)\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    training, test = splitData(dataset, sRatio)\n",
    "    redshift = [i[-2] for i in test]\n",
    "    redshift_ranges = [1 if i <= 0.033 else 2 if i >=\n",
    "                       0.004 else 3 for i in redshift]\n",
    "    [i.pop(-2) for i in training]\n",
    "    [i.pop(-2) for i in test]\n",
    "    PV = summary(training)\n",
    "    y_true, predictions = getPredictions(PV, test)\n",
    "    rs = pd.Series(redshift_ranges)\n",
    "    p = pd.Series(predictions)\n",
    "    corrl = rs.corr(p)\n",
    "    cm = confusion_matrix(y_true, predictions)\n",
    "    # print('\\n\\n Confusion Matrix \\n')\n",
    "    # print('\\n'.join([''.join(['{:4}'.format(item) for item in row]) for row in cm]))\n",
    "    FP = cm.sum(axis=0) - np.diag(cm)\n",
    "    FN = cm.sum(axis=1) - np.diag(cm)\n",
    "    TP = np.diag(cm)\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "    # print('False Positives\\n{}'.format(FP))\n",
    "    # print('False Negatives\\n{}'.format(FN))\n",
    "    # print('True Positives\\n{}'.format(TP))\n",
    "    # print('True Negatives\\n{}'.format(TN))\n",
    "    # TPR = TP/(TP+FN)\n",
    "    # print('Sensitivity \\n {}'.format(TPR))\n",
    "    # TNR = TN/(TN+FP)\n",
    "    # print('Specificity \\n {}'.format(TNR))\n",
    "    #Precision = TP/(TP+FP)\n",
    "    # print('Precision \\n{}'.format(Precision))\n",
    "    #Recall = TP/(TP+FN)\n",
    "    # print('Recall \\n{}'.format(Recall))\n",
    "    Acc = (TP+TN)/(TP+TN+FP+FN)\n",
    "    # print('Accuracy \\n{}'.format(Acc))\n",
    "    # Fscore = 2*(Precision*Recall)/(Precision+Recall)\n",
    "    # print('Fscore \\n{}'.format(Fscore))\n",
    "    return Acc,corrl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import model_selection\n",
    "clf = GaussianNB()\n",
    "dataset=df1.values.tolist()\n",
    "X = np.array(df1.drop('class',axis=1).values)\n",
    "y = np.array(df1['class'].values)\n",
    "scores = model_selection.cross_val_score(clf, X, y, cv=4, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DataSet  Accuracy  Correlation\n",
      "0      df  0.930769     0.679803\n",
      "1     df1  0.900000     0.379566\n",
      "2     df2  0.892308     0.516984\n",
      "3     df3  0.900000     0.384900\n",
      "4     df4  0.953846     0.661524\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "if __name__ == \"__main__\":\n",
    "    file = 'cat1.csv'\n",
    "    df = pd.read_csv(file)\n",
    "    df.drop(labels=['galex_objid', 'sdss_objid'], axis=1, inplace=True)\n",
    "    class_column = df['class']\n",
    "    srs_column = df['spectrometric_redshift']\n",
    "    df = df.drop(labels=['spectrometric_redshift', 'pred', 'class'], axis=1)\n",
    "    df['spectrometric_redshift'] = srs_column\n",
    "    df['class'] = class_column\n",
    "    \n",
    "    df4 = df.drop(labels=['extinction_u','extinction_g','extinction_r','extinction_i','extinction_z'],axis=1)\n",
    "    df2 = df.drop(labels=['nuv-u','nuv-g','nuv-r','nuv-i','nuv-z','u-g','u-r','u-i','u-z','g-r','g-i','g-z','r-i','r-z','i-z'],axis=1)\n",
    "    df3 = df.drop(labels=['fuv-nuv','fuv-u','fuv-g','fuv-r','fuv-i','fuv-z'],axis=1)\n",
    "    df1 = df.drop(labels=['u','g','i','z','extinction_u','extinction_g','extinction_r','extinction_i','extinction_z','nuv-u','nuv-g','nuv-i','nuv-z','u-g','u-r','u-i','u-z','g-r','g-i','g-z','r-i','r-z','i-z','fuv-nuv','fuv-u','fuv-g','fuv-r','fuv-i','fuv-z'],axis=1)\n",
    "    dataset = df.values.tolist()\n",
    "    random.seed(41)\n",
    "    \n",
    "    df_results = []\n",
    "    Acc,corrl = main(dataset)\n",
    "    Acc1,corrl1 = main(df1.values.tolist())\n",
    "    Acc2,corrl2 = main(df2.values.tolist())\n",
    "    Acc3,corrl3 = main(df3.values.tolist())\n",
    "    Acc4,corrl4 = main(df4.values.tolist())\n",
    "    data = {'DataSet':['df','df1','df2','df3','df4'], 'Accuracy':[Acc[0],Acc1[0],Acc2[0],Acc3[0],Acc4[0]], 'Correlation':[corrl,corrl1,corrl2,corrl3,corrl4]}\n",
    "    df_results = pd.DataFrame(data)\n",
    "    print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.014\n",
      "Average bias: 0.015\n",
      "Average variance: 0.005\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "X = np.array(df.drop('class',axis=1).values)\n",
    "y = np.array(df['class'].values)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=41,stratify=y)\n",
    "model = GaussianNB()\n",
    "model.fit(X,y)\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        model, X_train, y_train, X_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=41)\n",
    "avg_loss=avg_expected_loss\n",
    "avg_bias=avg_bias\n",
    "avg_var=avg_var\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.007\n",
      "Average bias: 0.005\n",
      "Average variance: 0.003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "X = np.array(df1.drop('class',axis=1).values)\n",
    "y = np.array(df1['class'].values)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=41,stratify=y)\n",
    "model = GaussianNB()\n",
    "model.fit(X,y)\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        model, X_train, y_train, X_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=41)\n",
    "avg_loss1=avg_expected_loss\n",
    "avg_bias1=avg_bias\n",
    "avg_var1=avg_var\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.024\n",
      "Average bias: 0.021\n",
      "Average variance: 0.005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "X = np.array(df2.drop('class',axis=1).values)\n",
    "y = np.array(df2['class'].values)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=41,stratify=y)\n",
    "model = GaussianNB()\n",
    "model.fit(X,y)\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        model, X_train, y_train, X_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=41)\n",
    "avg_loss2=avg_expected_loss\n",
    "avg_bias2=avg_bias\n",
    "avg_var2=avg_var\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.018\n",
      "Average bias: 0.021\n",
      "Average variance: 0.006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "X = np.array(df3.drop('class',axis=1).values)\n",
    "y = np.array(df3['class'].values)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=41,stratify=y)\n",
    "model = GaussianNB()\n",
    "model.fit(X,y)\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        model, X_train, y_train, X_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=41)\n",
    "avg_loss3=avg_expected_loss\n",
    "avg_bias3=avg_bias\n",
    "avg_var3=avg_var\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.012\n",
      "Average bias: 0.010\n",
      "Average variance: 0.005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "X = np.array(df4.drop('class',axis=1).values)\n",
    "y = np.array(df4['class'].values)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=41,stratify=y)\n",
    "model = GaussianNB()\n",
    "model.fit(X,y)\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        model, X_train, y_train, X_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=41)\n",
    "avg_loss4=avg_expected_loss\n",
    "avg_bias4=avg_bias\n",
    "avg_var4=avg_var\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DataSet  Avg_exp_loss  Avg_Bias  Avg_Variance\n",
      "0      df      0.013744  0.010256      0.004846\n",
      "1     df1      0.006744  0.005128      0.003462\n",
      "2     df2      0.023513  0.020513      0.004590\n",
      "3     df3      0.017513  0.020513      0.006128\n",
      "4     df4      0.011513  0.010256      0.004846\n"
     ]
    }
   ],
   "source": [
    "    bv_results = []\n",
    "    data = {'DataSet':['df','df1','df2','df3','df4'], 'Avg_exp_loss':[avg_loss,avg_loss1,avg_loss2,avg_loss3,avg_loss4], 'Avg_Bias':[avg_bias,avg_bias1,avg_bias2,avg_bias3,avg_bias4], 'Avg_Variance':[avg_var,avg_var1,avg_var2,avg_var3,avg_var4]}\n",
    "    bv_results = pd.DataFrame(data)\n",
    "    print(bv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
