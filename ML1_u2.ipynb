{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCsv(filename):\n",
    "    lines=csv.reader(open(filename, 'r'))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [x for x in dataset[i]]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std(numbers):\n",
    "    if len(numbers) == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        avg = mean(numbers)\n",
    "        variance = sum([pow(x-avg,2) for x in numbers]) / float(len(numbers)-1)\n",
    "        return math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(dataset, sRatio):\n",
    "    trainSize = int(len(dataset) * sRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return [trainSet, copy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(dataset):\n",
    "    foreveryclass=[]\n",
    "    for attribute in zip(*dataset):\n",
    "        x = mean(attribute)\n",
    "        y = std(attribute)\n",
    "        foreveryclass.append([x,y])\n",
    "    del foreveryclass[-1]\n",
    "    return foreveryclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassData(dataset):\n",
    "    classdivision = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if(vector[-1] not in classdivision):\n",
    "            classdivision[vector[-1]] = []\n",
    "        classdivision[vector[-1]].append(vector)\n",
    "    return classdivision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(dataset):\n",
    "    divided = ClassData(dataset)\n",
    "    PValues = {}\n",
    "    for classValue, instances in divided.items():\n",
    "        PValues[classValue] = process(instances)\n",
    "    return PValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prob(x, mean, stdev):\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassProb(ProcessValues, inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in ProcessValues.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = inputVector[i]\n",
    "            probabilities[classValue] *=Prob(x,mean,stdev)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ProcessValues , inputVector):\n",
    "    probabilities = ClassProb(ProcessValues, inputVector)\n",
    "    bestLabel , bestProb = None,-1\n",
    "    for classValue , probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(ProcessValue , testSet):\n",
    "    predictions = []\n",
    "    y_true = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(ProcessValue , testSet[i])\n",
    "        predictions.append(result)\n",
    "    for i in range(len(testSet)):\n",
    "        vector = testSet[i]\n",
    "        y_true.append(vector[-1])\n",
    "    return [y_true , predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet , predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i]:\n",
    "            correct +=1\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnvrt2flot(dataset):\n",
    "    d=[]\n",
    "    for i in dataset:\n",
    "        d.append(list(map(float,i)))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main(dataset):\n",
    "    sRatio = 0.80\n",
    "    #dataset = loadCsv(file)\n",
    "    #dataset = dataset[1:]\n",
    "    #dataset = cnvrt2flot(dataset)\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    training, test = splitData(dataset, sRatio)\n",
    "    redshift = [i[-2] for i in test]\n",
    "    redshift_ranges = [1 if i <= 0.033 else 2 if i >=\n",
    "                       0.004 else 3 for i in redshift]\n",
    "    [i.pop(-2) for i in training]\n",
    "    [i.pop(-2) for i in test]\n",
    "    PV = summary(training)\n",
    "    y_true, predictions = getPredictions(PV, test)\n",
    "    rs = pd.Series(redshift_ranges)\n",
    "    p = pd.Series(predictions)\n",
    "    print(\"corr:{}\".format(rs.corr(p)))\n",
    "    cm = confusion_matrix(y_true, predictions)\n",
    "    # print('\\n\\n Confusion Matrix \\n')\n",
    "    # print('\\n'.join([''.join(['{:4}'.format(item) for item in row]) for row in cm]))\n",
    "    FP = cm.sum(axis=0) - np.diag(cm)\n",
    "    FN = cm.sum(axis=1) - np.diag(cm)\n",
    "    TP = np.diag(cm)\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "    # print('False Positives\\n{}'.format(FP))\n",
    "    # print('False Negatives\\n{}'.format(FN))\n",
    "    # print('True Positives\\n{}'.format(TP))\n",
    "    # print('True Negatives\\n{}'.format(TN))\n",
    "    # TPR = TP/(TP+FN)\n",
    "    # print('Sensitivity \\n {}'.format(TPR))\n",
    "    # TNR = TN/(TN+FP)\n",
    "    # print('Specificity \\n {}'.format(TNR))\n",
    "    # Precision = TP/(TP+FP)\n",
    "    # print('Precision \\n{}'.format(Precision))\n",
    "    # Recall = TP/(TP+FN)\n",
    "    # print('Recall \\n{}'.format(Recall))\n",
    "    Acc = (TP+TN)/(TP+TN+FP+FN)\n",
    "    # print('Accuracy \\n{}'.format(Acc))\n",
    "    # Fscore = 2*(Precision*Recall)/(Precision+Recall)\n",
    "    # print('Fscore \\n{}'.format(Fscore))\n",
    "    return Acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "corr:0.711351389345835\n",
      "All Columns\n",
      "Accuracy \n",
      "0.9384615384615385\n",
      "-------------------------\n",
      "corr:0.46004420222127024\n",
      "First set of Columns\n",
      "Accuracy \n",
      "0.9307692307692308\n",
      "-------------------------\n",
      "corr:0.5343059528700057\n",
      "Second set of Columns\n",
      "Accuracy \n",
      "0.9\n",
      "-------------------------\n",
      "corr:0.36533101260154843\n",
      "Second set of Columns\n",
      "Accuracy \n",
      "0.8923076923076924\n",
      "-------------------------\n",
      "corr:0.581834629888877\n",
      "Second set of Columns\n",
      "Accuracy \n",
      "0.9461538461538461\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file = 'cat1.csv'\n",
    "    df = pd.read_csv(file)\n",
    "    df.drop(labels=['galex_objid', 'sdss_objid'], axis=1)\n",
    "    class_column = df['class']\n",
    "    srs_column = df['spectrometric_redshift']\n",
    "    df = df.drop(labels=['spectrometric_redshift', 'pred', 'class'], axis=1)\n",
    "    df['spectrometric_redshift'] = srs_column\n",
    "    df['class'] = class_column\n",
    "    \n",
    "    df4 = df.drop(labels=['extinction_u','extinction_g','extinction_r','extinction_i','extinction_z'],axis=1)\n",
    "    df2 = df.drop(labels=['nuv-u','nuv-g','nuv-r','nuv-i','nuv-z','u-g','u-r','u-i','u-z','g-r','g-i','g-z','r-i','r-z','i-z'],axis=1)\n",
    "    df3 = df.drop(labels=['fuv-nuv','fuv-u','fuv-g','fuv-r','fuv-i','fuv-z'],axis=1)\n",
    "    df1 = df.drop(labels=['u','g','i','z','extinction_u','extinction_g','extinction_r','extinction_i','extinction_z','nuv-u','nuv-g','nuv-i','nuv-z','u-g','u-r','u-i','u-z','g-r','g-i','g-z','r-i','r-z','i-z','fuv-u','fuv-g','fuv-r','fuv-i','fuv-z'],axis=1)\n",
    "    \n",
    "        #dataset = df1.values.tolist()\n",
    "    print(\"========================\")\n",
    "    dataset = df.values.tolist()\n",
    "    random.seed(41)\n",
    "    Acc = main(dataset)\n",
    "    print(\"All Columns\")\n",
    "    print('Accuracy \\n{}'.format(Acc[0]))\n",
    "        #print(\"seed:\"+str(i))\n",
    "    print(\"-------------------------\")\n",
    "        \n",
    "    Acc = main(df1.values.tolist())\n",
    "    print(\"First set of Columns\")\n",
    "    print('Accuracy \\n{}'.format(Acc[0]))\n",
    "        #print(\"seed:\"+str(i))\n",
    "    print(\"-------------------------\")\n",
    "    Acc = main(df2.values.tolist())\n",
    "    print(\"Second set of Columns\")\n",
    "    print('Accuracy \\n{}'.format(Acc[0]))\n",
    "        #print(\"seed:\"+str(i))\n",
    "    print(\"-------------------------\")\n",
    "    Acc = main(df3.values.tolist())\n",
    "    print(\"Third set of Columns\")\n",
    "    print('Accuracy \\n{}'.format(Acc[0]))\n",
    "        #print(\"seed:\"+str(i))\n",
    "    print(\"-------------------------\")\n",
    "    Acc = main(df4.values.tolist())\n",
    "    print(\"Fourth set of Columns\")\n",
    "    print('Accuracy \\n{}'.format(Acc[0]))\n",
    "        #print(\"seed:\"+str(i))\n",
    "    print(\"-------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 448 is out of bounds for axis 0 with size 195",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-788f9c676608>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(model,X_train, X_test, y_train, y_test,loss='0-1_loss',\n\u001b[1;32m---> 14\u001b[1;33m                                                             random_seed=41)\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Average expected loss: %.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mavg_expected_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mlxtend\\evaluate\\bias_variance_decomp.py\u001b[0m in \u001b[0;36mbias_variance_decomp\u001b[1;34m(estimator, X_train, y_train, X_test, y_test, loss, num_rounds, random_seed)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mX_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_boot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_draw_bootstrap_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_boot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mall_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mlxtend\\evaluate\\bias_variance_decomp.py\u001b[0m in \u001b[0;36m_draw_bootstrap_sample\u001b[1;34m(rng, X, y)\u001b[0m\n\u001b[0;32m     14\u001b[0m                                    \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_indices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                                    replace=True)\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbootstrap_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbootstrap_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 448 is out of bounds for axis 0 with size 195"
     ]
    }
   ],
   "source": [
    "\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "\n",
    "dataset=df1.values.tolist()\n",
    "X = np.array(df1.drop('class',axis=1).values)\n",
    "y = np.array(df1['class'].values)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=41,stratify=y)\n",
    "\n",
    "model=GaussianNB()\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(model,X_train, X_test, y_train, y_test,loss='0-1_loss',\n",
    "                                                            random_seed=41)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import model_selection\n",
    "clf = GaussianNB()\n",
    "dataset=df1.values.tolist()\n",
    "X = np.array(df1.drop('class',axis=1).values)\n",
    "y = np.array(df1['class'].values)\n",
    "scores = model_selection.cross_val_score(clf, X, y, cv=4, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-1507cdb098b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"========================\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mAcc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m41\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All Columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy \\n{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAcc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file = 'cat1.csv'\n",
    "    df = pd.read_csv(file)\n",
    "    class_column = df['class']\n",
    "    df = df.drop(labels=['spectrometric_redshift','pred','class'],axis=1)\n",
    "    df['class'] = class_column\n",
    "    df4 = df.drop(labels=['extinction_u','extinction_g','extinction_r','extinction_i','extinction_z'],axis=1)\n",
    "    df2 = df.drop(labels=['nuv-u','nuv-g','nuv-r','nuv-i','nuv-z','u-g','u-r','u-i','u-z','g-r','g-i','g-z','r-i','r-z','i-z'],axis=1)\n",
    "    df3 = df.drop(labels=['fuv-nuv','fuv-u','fuv-g','fuv-r','fuv-i','fuv-z'],axis=1)\n",
    "    df1 = df.drop(labels=['u','g','i','z','extinction_u','extinction_g','extinction_r','extinction_i','extinction_z','nuv-u','nuv-g','nuv-i','nuv-z','u-g','u-r','u-i','u-z','g-r','g-i','g-z','r-i','r-z','i-z','fuv-u','fuv-g','fuv-r','fuv-i','fuv-z'],axis=1)\n",
    "    \n",
    "    print(\"========================\")\n",
    "    dataset = df.values.tolist()\n",
    "    Acc = main(dataset)\n",
    "    print(\"All Columns\")\n",
    "    print('Accuracy \\n{}'.format(Acc[0]))\n",
    "    #print(\"seed:\"+str(i))\n",
    "    print(\"-------------------------\")\n",
    "    Acc = main(df1.values.tolist(random))\n",
    "    print(\"First set of Columns\")\n",
    "    print('Accuracy \\n{}'.format(Acc[0]))\n",
    "    #print(\"seed:\"+str(i))\n",
    "    print(\"-------------------------\")\n",
    "    Acc = main(df2.values.tolist())\n",
    "    print(\"Second set of Columns\")\n",
    "    print('Accuracy \\n{}'.format(Acc[0]))\n",
    "    #print(\"seed:\"+str(i))\n",
    "    print(\"-------------------------\")\n",
    "    Acc = main(df3.values.tolist())\n",
    "    print(\"Second set of Columns\")\n",
    "    print('Accuracy \\n{}'.format(Acc[0]))\n",
    "    #print(\"seed:\"+str(i))\n",
    "    print(\"-------------------------\")\n",
    "    Acc = main(df4.values.tolist())\n",
    "    print(\"Second set of Columns\")\n",
    "    print('Accuracy \\n{}'.format(Acc[0]))\n",
    "    #print(\"seed:\"+str(i))\n",
    "    print(\"-------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
